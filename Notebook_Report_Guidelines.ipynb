{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "meaningful-saturn",
   "metadata": {},
   "source": [
    "# PDV Notebook Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-adaptation",
   "metadata": {},
   "source": [
    "## How to Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-flash",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-acoustic",
   "metadata": {},
   "source": [
    "Our notebooks are now public.\n",
    "\n",
    "- I would imagine that anyone seriously interested in our reports, would also be interested in our notebooks.\n",
    "- Our notebooks (and reports) are only useful in so far as they are read-able.\n",
    "- When someone reads a notebook, they will not give it the same attention as you did when writing it, as such it should be clear, concise.\n",
    "- Every chunk of code should either have a title in markdown explaining ir, or a comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-revolution",
   "metadata": {},
   "source": [
    "### Joining files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-fellowship",
   "metadata": {},
   "source": [
    "- You can create your own unique ID in VEST's file!\n",
    "- You should delete a lot of the work you do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-archives",
   "metadata": {},
   "source": [
    "### Things to keep in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-factory",
   "metadata": {},
   "source": [
    "Some key numbers, that should be readily explained in the notebook:\n",
    "- Vote totals for entire races (and any differences)\n",
    "- Vote totals across counties (and any differences)\n",
    "- Vote totals precinct-by-precinct (and any differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-arrangement",
   "metadata": {},
   "source": [
    "### Joining files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-transportation",
   "metadata": {},
   "source": [
    "If you are able to easily join the election results to the shapefile, try to join those first before checking election results.\n",
    "\n",
    "What is \"easy\"?\n",
    "- Try to do it in 15 min, if you can't, then first focus on matching the names of the election result precincts to VEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-container",
   "metadata": {},
   "source": [
    "### Steps to recreate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-amount",
   "metadata": {},
   "source": [
    "#### VEST's steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-nebraska",
   "metadata": {},
   "source": [
    "For files, if there are many, or using the file would require manually adjusting them boundaries of a shapefile, do not try to find it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-burlington",
   "metadata": {},
   "source": [
    "If there are steps that seem obvious from looking at the source files try to carry them out:\n",
    "- Names with \"CD\" in them\n",
    "- Names with two precincts joined with \"&\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-hypothetical",
   "metadata": {},
   "source": [
    "## How to Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-dispute",
   "metadata": {},
   "source": [
    "Resort your columns to match VEST's final file\n",
    "Give your variables meaningful name (especially for VEST's file, and your eleciton results / shapefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-cambridge",
   "metadata": {},
   "source": [
    "## Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-monthly",
   "metadata": {},
   "source": [
    "### Setup / Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bd3d2",
   "metadata": {},
   "source": [
    "#### 1) Top of a report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff286c35-e1fd-4c4b-b78b-65d74c5c98bd",
   "metadata": {},
   "source": [
    "# PARTNER STATE_ABBRV YEAR (XXXX)\n",
    "# Ex. VEST OH 2020\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de86d0-8567-4ab6-92f8-9faf2c77c253",
   "metadata": {},
   "source": [
    "## VEST Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116d734-cc64-4ada-9d96-ee0df51db943",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "#### Election Results\n",
    "(Paste VEST's documentation on where it sourced the election results here)\n",
    "\n",
    "#### Shapefiles\n",
    "(Paste VEST's documentation on where it sourced the shapefiles here)\n",
    "\n",
    "### Processing\n",
    "(Paste VEST's documentation on processing the file here)\n",
    "\n",
    "### Races\n",
    "(Paste the names of the variarbles here)\n",
    "\n",
    "#### (Note: delete for report - please add in double spaces after the lines above so they appear as separate lines in markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d19c98f-ed5b-4779-9ba4-b714504a82d5",
   "metadata": {},
   "source": [
    "## Election Result Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58708ae-bd39-4592-a6ab-b133adc49ad8",
   "metadata": {},
   "source": [
    "### Load in VEST file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d92a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ex. vest_oh_20 = gp.read_file(\"./raw-from-source/VEST/oh_2020/oh_2020.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef9e60",
   "metadata": {},
   "source": [
    "*************** End of Section *************** (this should not go in a report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc38b6c",
   "metadata": {},
   "source": [
    "#### 2) Packages to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np \n",
    "import os\n",
    "import fiona\n",
    "from statistics import mean, median\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-headset",
   "metadata": {},
   "source": [
    "#### 3) Creating a dictionary from a two-column csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-terminal",
   "metadata": {},
   "source": [
    "This is helpful for when you create your dictionary of name changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_csv = pd.read_csv(\"example.csv\")\n",
    "example_fips_dict = dict(zip(example_csv[\"COLUMN_1\"],example_csv[\"COLUMN_2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6afb96",
   "metadata": {},
   "source": [
    "#### 4) Merging\n",
    "\n",
    "The 'validate' parameter will prevent the merge from happening unless the \"join_col\" value is unique in both dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_1,df_2,how='outer',on=\"join_col\",indicator=True,validate='1:1')\n",
    "print(merged_df[\"_merge\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-wireless",
   "metadata": {},
   "source": [
    "#### 5) Creating a FIPs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the nationwide FIPS file\n",
    "fips_file = pd.read_csv(\"./raw-from-source/FIPS/US_FIPS_Codes.csv\")\n",
    "fips_file = fips_file[fips_file[\"State\"]==\"YOUR_STATE_HERE\"]\n",
    "fips_file[\"FIPS County\"]=fips_file[\"FIPS County\"].astype(str)\n",
    "\n",
    "#Make the FIPS three digits\n",
    "fips_file[\"FIPS County\"]=fips_file[\"FIPS County\"].str.zfill(3)\n",
    "\n",
    "#Create the dictionary\n",
    "STATE_ABBREVIATION_fips_dict = dict(zip(fips_file[\"County Name\"],fips_file[\"FIPS County\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-transport",
   "metadata": {},
   "source": [
    "#### 6) Importing census redistricting phase 2 shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When downloading from the Census redistricing data program, these use a FIPS code to identify counties\n",
    "fips_codes = [\"13135\",\"13067\",\"13089\"]\n",
    "\n",
    "#Combine all the data from separate files into one\n",
    "li = []\n",
    "for i in fips_codes:\n",
    "    ref = \"./raw-from-source/Shapefiles/Census/partnership_shapefiles_19v2_\"\n",
    "    file_ref = ref+i+\"/PVS_19_v2_vtd_\"+i+\".shp\"\n",
    "    file_prev = gp.read_file(file_ref)\n",
    "    #print(file_prev.shape)\n",
    "    li.append(file_prev)\n",
    "shapefiles_census = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-pontiac",
   "metadata": {},
   "source": [
    "#### 7) Finding zero-vote precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = ['RACE_1','RACE_2',...]\n",
    "empty_precincts = []\n",
    "for index, row in ELECTION_DATAFRAME.iterrows():\n",
    "    number_of_zero_vote_races = 0\n",
    "    for race in data_columns:\n",
    "        if (row[race]==0):\n",
    "            number_of_zero_vote_races += 1\n",
    "    if(number_of_zero_vote_races == len(data_columns)):\n",
    "        empty_precincts.append(row[\"IDENTIFIER\"])\n",
    "print(len(empty_precincts))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-binary",
   "metadata": {},
   "source": [
    "### Checking Election Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-sport",
   "metadata": {},
   "source": [
    "#### 1) Race Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statewide_totals_check(partner_df,source_df,column_list):\n",
    "    print(\"***Statewide Totals Check***\")\n",
    "    for race in column_list:\n",
    "        if (partner_df[race].sum()- source_df[race].sum() != 0):\n",
    "            print(race+\" has a difference of \"+str(partner_df[race].sum()-source_df[race].sum())+\" votes\")\n",
    "            print(\"\\tVEST: \"+str(partner_df[race].sum())+\" votes\")\n",
    "            print(\"\\tSOURCES: \"+str(source_df[race].sum())+\" votes\")\n",
    "        else:\n",
    "            print(race + \" is equal\", \"\\tVEST / RDH: \" + str(partner_df[race].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-october",
   "metadata": {},
   "source": [
    "#### 2) County-by-County Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_totals_check(partner_df,source_df,column_list,county_col,full_print=False):\n",
    "    print(\"***Countywide Totals Check***\")\n",
    "    print(\"\")\n",
    "    diff_counties=[]\n",
    "    for race in column_list:\n",
    "        diff = partner_df.groupby([county_col]).sum()[race]-source_df.groupby([county_col]).sum()[race]\n",
    "        for val in diff[diff != 0].index.values.tolist():\n",
    "            if val not in diff_counties:\n",
    "                diff_counties.append(val)\n",
    "        if len(diff[diff != 0]!=0):   \n",
    "            print(race + \" contains differences in these counties:\")\n",
    "            for val in diff[diff != 0].index.values.tolist():\n",
    "                county_differences = diff[diff != 0]\n",
    "                print(\"\\t\"+val+\" has a difference of \"+str(county_differences[val])+\" votes\")\n",
    "                print(\"\\t\\tVEST: \"+str(partner_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "                print(\"\\t\\tSOURCES: \"+str(source_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "            if (full_print):\n",
    "                for val in diff[diff == 0].index.values.tolist():\n",
    "                    county_similarities = diff[diff == 0]\n",
    "                    print(\"\\t\"+val + \": \"+ str(partner_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "        else:\n",
    "            print(race + \" is equal across all counties\")\n",
    "            if (full_print):\n",
    "                for val in diff[diff == 0].index.values.tolist():\n",
    "                    county_similarities = diff[diff == 0]\n",
    "                    print(\"\\t\"+val + \": \"+ str(partner_df.groupby([county_col]).sum().loc[val,race])+\" votes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-yahoo",
   "metadata": {},
   "source": [
    "#### 3) Precinct-by-Precinct Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precinct_votes_check(merged_df,column_list,vest_on_left,name_col,print_level=0):\n",
    "    merged_df = merged_df.sort_values(by=[name_col],inplace=False)\n",
    "    matching_rows = 0\n",
    "    different_rows = 0\n",
    "    diff_list=[]\n",
    "    diff_values = []\n",
    "    max_diff = 0\n",
    "    for index,row in merged_df.iterrows():\n",
    "        same = True\n",
    "        for i in column_list:\n",
    "            left_data = i + \"_x\"\n",
    "            right_data = i + \"_y\"\n",
    "            if ((row[left_data] is None) or (row[right_data] is None) or (np.isnan(row[right_data])or(np.isnan(row[left_data])))):\n",
    "                print(\"FIX NaN value at: \", row[name_col])\n",
    "                return;\n",
    "            diff = abs(row[left_data]-row[right_data])\n",
    "            if (diff>0):\n",
    "                same = False\n",
    "                diff_values.append(abs(diff))\n",
    "                if (diff>max_diff):\n",
    "                    max_diff = diff\n",
    "            if(diff>print_level):\n",
    "                if (vest_on_left):\n",
    "                    print(i, \"{:.>72}\".format(row[name_col]), \"(V)\",\"{:.>5}\".format(int(row[left_data])),\" (S){:.>5}\".format(int(row[right_data])),\"(D):{:>5}\".format(int(row[left_data]-row[right_data])))                           \n",
    "                else:\n",
    "                    print(i, \"{:.>72}\".format(row[name_col]), \"(S)\",\"{:.>5}\".format(int(row[left_data])),\" (V){:.>5}\".format(int(row[right_data])),\"(D):{:>5}\".format(int(row[left_data]-row[right_data])))\n",
    "        if(same != True):\n",
    "            different_rows +=1\n",
    "            diff_list.append(row[name_col])\n",
    "        else:\n",
    "            matching_rows +=1\n",
    "    print(\"\")\n",
    "    print(\"There are \", len(merged_df.index),\" total rows\")\n",
    "    print(different_rows,\" of these rows have election result differences\")\n",
    "    print(matching_rows,\" of these rows are the same\")\n",
    "    print(\"\")\n",
    "    print(\"The max difference between any one shared column in a row is: \", max_diff)\n",
    "    if(len(diff_values)!=0):\n",
    "        print(\"The average difference is: \", str(sum(diff_values)/len(diff_values)))\n",
    "    count_big_diff = len([i for i in diff_values if i > 10])\n",
    "    print(\"There are \", str(count_big_diff), \"precinct results with a difference greater than 10\")\n",
    "    print(\"\")\n",
    "    print(\"All precincts containing differences:\")\n",
    "    diff_list.sort()\n",
    "    print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-magic",
   "metadata": {},
   "source": [
    "#### Allocating absentee votes\n",
    "\n",
    "Note: This implementation of the allocation solves for the cases where non-zero votes are allocated to a set of precincts that have zero total votes for that race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_absentee(df_receiving_votes,df_allocating,column_list,col_allocating,allocating_to_all_empty_precs=False):\n",
    "    \"\"\"Allocates votes proportionally to precincts, usually by share of precinct-reported vote\n",
    "\n",
    "    Args:\n",
    "      df_receiving_votes: DataFrame with precinct-level votes\n",
    "      df_allocating: DataFrame with the votes to allocate\n",
    "      column_list: List of races that votes are being allocated for\n",
    "      col_allocating: String referring to what level the allocation occurs at (most often county)\n",
    "      allocating_to_all_empty_precs: Boolean for special case where all votes in df_receiving_votes are 0\n",
    "\n",
    "    Returns:\n",
    "      The precinct-level votes dataframe (df_receiving_votes) with the allocated votes\n",
    "    \"\"\"\n",
    "    \n",
    "    df_receiving_votes = df_receiving_votes.fillna(0)\n",
    "    original_cols = list(df_receiving_votes.columns)\n",
    "    \n",
    "    #Add in the \"Total Votes column\"\n",
    "    if (allocating_to_all_empty_precs):\n",
    "        df_receiving_votes.loc[:,\"Total_Votes\"]=1\n",
    "    else:\n",
    "        df_receiving_votes.loc[:,\"Total_Votes\"]=0\n",
    "        for race in column_list:\n",
    "            df_receiving_votes.loc[:,\"Total_Votes\"]+=df_receiving_votes.loc[:,race]\n",
    "    \n",
    "    #Create the needed dataframes\n",
    "    precinct_specific_totals = pd.DataFrame(df_receiving_votes.groupby([col_allocating]).sum())\n",
    "    precinct_specific_totals.reset_index(drop=False,inplace=True)\n",
    "    to_dole_out_totals = pd.DataFrame(df_allocating.groupby([col_allocating]).sum())\n",
    "    to_dole_out_totals.reset_index(drop=False,inplace=True)\n",
    "    \n",
    "    #Add in total sum check\n",
    "    sum_dataframe = pd.DataFrame(columns=precinct_specific_totals.columns)\n",
    "    for i in column_list:\n",
    "        total_votes = precinct_specific_totals.loc[:,i].sum()+to_dole_out_totals.loc[:,i].sum()\n",
    "        sum_dataframe.at[0,i]=total_votes.astype(int)\n",
    "    \n",
    "    #Check the allocating to empty precincts code\n",
    "    if (allocating_to_all_empty_precs):\n",
    "        for i in column_list:\n",
    "            if(sum(precinct_specific_totals[i])!=0):\n",
    "                print(\"Allocating to all empty precincts parameter incorrect\")\n",
    "                break\n",
    "    \n",
    "    #Print out any instances where the allocation, as written, won't work\n",
    "    special_allocation_needed = []\n",
    "    for index, row in precinct_specific_totals.iterrows():\n",
    "        for race in column_list:\n",
    "            if (row[race]==0):\n",
    "                race_district = row[col_allocating]\n",
    "                if race_district in to_dole_out_totals[col_allocating].unique():\n",
    "                    to_allocate = int(to_dole_out_totals.loc[to_dole_out_totals[col_allocating]==race_district][race])\n",
    "                    if (to_allocate != 0):\n",
    "                        special_allocation_needed.append([race_district,race])\n",
    "                        if(row[\"Total_Votes\"]==0):\n",
    "                            precinct_specific_totals.loc[index,\"Total_Votes\"]=1\n",
    "                            col_val = row[col_allocating]\n",
    "                            df_receiving_votes.loc[df_receiving_votes[col_allocating]==col_val,\"Total_Votes\"]=1\n",
    "\n",
    "    #Create some new columns for each of these races to deal with the allocation\n",
    "    for race in column_list:\n",
    "        add_var = race+\"_add\"\n",
    "        rem_var = race+\"_rem\"\n",
    "        floor_var = race+\"_floor\"\n",
    "        df_receiving_votes.loc[:,add_var]=0.0\n",
    "        df_receiving_votes.loc[:,rem_var]=0.0\n",
    "        df_receiving_votes.loc[:,floor_var]=0.0\n",
    "\n",
    "    #Iterate over the rows\n",
    "    #Note this function iterates over the dataframe two times so the rounded vote totals match the totals to allocate\n",
    "    for index, row in df_receiving_votes.iterrows():\n",
    "        if row[col_allocating] in to_dole_out_totals[col_allocating].unique():\n",
    "            for race in column_list:\n",
    "                add_var = race+\"_add\"\n",
    "                rem_var = race+\"_rem\"\n",
    "                floor_var = race+\"_floor\"\n",
    "                #Grab the district\n",
    "                county_id = row[col_allocating]\n",
    "                if [county_id,race] in special_allocation_needed:\n",
    "                    #Get the denominator for the allocation - the summed \"total votes\" for precincts in that grouping\n",
    "                    denom = precinct_specific_totals.loc[precinct_specific_totals[col_allocating]==county_id][\"Total_Votes\"]\n",
    "                    #Get one of the numerators, how many districtwide votes to allocate\n",
    "                    numer = to_dole_out_totals.loc[to_dole_out_totals[col_allocating]==county_id][race]\n",
    "                    #Get the \"total votes\" for this particular precinct\n",
    "                    val = df_receiving_votes.at[index,\"Total_Votes\"]\n",
    "                    #Get the vote share, the precincts % of total precinct votes in the district times votes to allocate\n",
    "                else:\n",
    "                    #Get the denominator for the allocation (the precinct vote totals)\n",
    "                    denom = precinct_specific_totals.loc[precinct_specific_totals[col_allocating]==county_id][race]\n",
    "                    #Get one of the numerators, how many districtwide votes to allocate\n",
    "                    numer = to_dole_out_totals.loc[to_dole_out_totals[col_allocating]==county_id][race]\n",
    "                    #Get the vote totals for this race in this precinct\n",
    "                    val = df_receiving_votes.at[index,race]\n",
    "                    #Get the vote share, the precincts % of total precinct votes in the district times votes to allocate\n",
    "                if ((float(denom)==0)):\n",
    "                    vote_share = 0\n",
    "                else:\n",
    "                    vote_share = (float(val)/float(denom))*float(numer)\n",
    "                df_receiving_votes.at[index,add_var] = vote_share\n",
    "                #Take the decimal remainder of the allocation\n",
    "                df_receiving_votes.at[index,rem_var] = vote_share%1\n",
    "                #Take the floor of the allocation\n",
    "                df_receiving_votes.at[index,floor_var] = np.floor(vote_share)\n",
    "\n",
    "    #After the first pass through, get the sums of the races by district to assist in the rounding            \n",
    "    first_allocation = pd.DataFrame(df_receiving_votes.groupby([col_allocating]).sum())\n",
    "\n",
    "    #Now we want to iterate district by district to work on rounding\n",
    "    county_list = list(to_dole_out_totals[col_allocating].unique()) \n",
    "\n",
    "    #Iterate over the district\n",
    "    for county in county_list:\n",
    "        for race in column_list:\n",
    "            add_var = race+\"_add\"\n",
    "            rem_var = race+\"_rem\"\n",
    "            floor_var = race+\"_floor\"\n",
    "            #County how many votes still need to be allocated (because we took the floor of all the initial allocations)\n",
    "            to_go = int(np.round((int(to_dole_out_totals.loc[to_dole_out_totals[col_allocating]==county][race])-first_allocation.loc[first_allocation.index==county,floor_var])))\n",
    "            #Grab the n precincts with the highest remainders and round these up, where n is the # of votes that still need to be allocated\n",
    "            for index in df_receiving_votes.loc[df_receiving_votes[col_allocating]==county][rem_var].nlargest(to_go).index:\n",
    "                df_receiving_votes.at[index,add_var] = np.ceil(df_receiving_votes.at[index,add_var])\n",
    "\n",
    "    #Iterate over every race again\n",
    "    for race in column_list:\n",
    "        add_var = race+\"_add\"\n",
    "        #Round every allocation down to not add fractional votes\n",
    "        df_receiving_votes.loc[:,add_var]=np.floor(df_receiving_votes.loc[:,add_var])\n",
    "        df_receiving_votes.loc[:,race]+=df_receiving_votes.loc[:,add_var]\n",
    "        df_receiving_votes.loc[:,race] = df_receiving_votes.loc[:,race].astype(int)\n",
    "        #print(race)\n",
    "        #print(sum_dataframe.loc[:,race].sum())\n",
    "        #print(df_receiving_votes.loc[:,race].sum())\n",
    "        if ((sum_dataframe.loc[:,race].sum()-df_receiving_votes.loc[:,race].sum()!=0)):\n",
    "            print(\"Some issue in allocating votes for:\", i)\n",
    "        \n",
    "    df_receiving_votes = df_receiving_votes[original_cols]\n",
    "\n",
    "    return df_receiving_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clark County = Clinton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-button",
   "metadata": {},
   "source": [
    "### Checking Shapefiles - IN PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print geopandas version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapefile_validater(merged_df,vest_df,area_print_num,name_col):\n",
    "    both = final_merge[final_merge[\"final_merge\"]==\"both\"]\n",
    "    vest_geoms = gp.GeoDataFrame(both,geometry=\"geometry_x\",crs=vest_vt_16.crs)\n",
    "    source_geoms = gp.GeoDataFrame(both,geometry=\"geometry_y\",crs=vest_vt_16.crs)\n",
    "    source_geoms = source_geoms.to_crs(3857)\n",
    "    vest_geoms = vest_geoms.to_crs(3857)\n",
    "    source_geoms[\"geometry_x\"]=source_geoms.buffer(0)\n",
    "    vest_geoms[\"geometry_y\"]=vest_geoms.buffer(0)\n",
    "    vals = source_geoms.geom_almost_equals(vest_geoms,decimal=0)\n",
    "    print(vals.value_counts())\n",
    "    \n",
    "    count = 0\n",
    "    area_list = []\n",
    "    for i in range(0,len(source_geoms)):\n",
    "        diff = source_geoms.iloc[[i]].symmetric_difference(vest_geoms.iloc[[i]])\n",
    "        intersection = source_geoms.iloc[[i]].intersection(vest_geoms.iloc[[i]])\n",
    "        area = float(diff.area/10e6)\n",
    "        area_list.append(area)\n",
    "\n",
    "        if (area > .1):\n",
    "            count += 1\n",
    "            name = source_geoms.iat[i,]\n",
    "\n",
    "            print(str(count)+\") For \" + name + \" difference in area is \" + str(area))\n",
    "            if (intersection.iloc[0].is_empty):\n",
    "                base = diff.plot(color=\"red\")\n",
    "                source_geoms.iloc[[i]].plot(color=\"orange\",ax=base)\n",
    "                vest_geoms.iloc[[i]].plot(color=\"blue\",ax=base)\n",
    "                base.set_title(name)\n",
    "            else:\n",
    "                base = diff.plot(color=\"red\")\n",
    "                source_geoms.iloc[[i]].plot(color=\"orange\",ax=base)\n",
    "                vest_geoms.iloc[[i]].plot(color=\"blue\",ax=base)\n",
    "                intersection.plot(color=\"green\",ax=base)\n",
    "                base.set_title(name)\n",
    "\n",
    "df = pd.DataFrame(area_list)\n",
    "print(df.shape)\n",
    "\n",
    "print(str(len(df[df[0]==0]))+\" precincts w/ a difference of 0 km^2\")\n",
    "print(str(len(df[(df[0]<.1) & (df[0]>0)]))+ \" precincts w/ a difference between 0 and .1 km^2\")\n",
    "print(str(len(df[(df[0]<.5) & (df[0]>=.1)]))+ \" precincts w/ a difference between .1 and .5 km^2\")\n",
    "print(str(len(df[(df[0]<1) & (df[0]>=.5)]))+ \" precincts w/ a difference between .5 and 1 km^2\")\n",
    "print(str(len(df[(df[0]<2) & (df[0]>=1)]))+ \" precincts w/ a difference between 1 and 2 km^2\")\n",
    "print(str(len(df[(df[0]<5) & (df[0]>=2)]))+ \" precincts w/ a difference between 2 and 5 km^2\")\n",
    "print(str(len(df[(df[0]>=5)]))+ \" precincts w/ a difference greater than 5 km^2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "convertible-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is OLD\n",
    "def allocate_absentee(df_receiving_votes,df_allocating,column_list,col_allocating):\n",
    "    original_cols = list(df_receiving_votes.columns)\n",
    "    \n",
    "    #Add in the \"Total Votes column\"\n",
    "    df_receiving_votes.loc[:,\"Total_Votes\"]=0\n",
    "    for race in column_list:\n",
    "        df_receiving_votes.loc[:,\"Total_Votes\"]+=df_receiving_votes.loc[:,race]\n",
    "    \n",
    "    #Create the needed dataframes\n",
    "    precinct_specific_totals = pd.DataFrame(df_receiving_votes.groupby([col_allocating]).sum())\n",
    "    precinct_specific_totals.reset_index(drop=False,inplace=True)\n",
    "    to_dole_out_totals = pd.DataFrame(df_allocating.groupby([col_allocating]).sum())\n",
    "    to_dole_out_totals.reset_index(drop=False,inplace=True)\n",
    "    \n",
    "    #Print out any instances where the allocation, as written, won't work\n",
    "    special_allocation_needed = []\n",
    "    for index, row in precinct_specific_totals.iterrows():\n",
    "        for race in column_list:\n",
    "            if (row[race]==0):\n",
    "                race_district = row[col_allocating]\n",
    "                if race_district in to_dole_out_totals[col_allocating].unique():\n",
    "                    to_allocate = int(to_dole_out_totals.loc[to_dole_out_totals[col_allocating]==race_district][race])\n",
    "                    if (to_allocate != 0):\n",
    "                        special_allocation_needed.append([race_district,race])\n",
    "    \n",
    "    #Create some new columns for each of these races to deal with the allocation\n",
    "    for race in column_list:\n",
    "        add_var = race+\"_add\"\n",
    "        rem_var = race+\"_rem\"\n",
    "        floor_var = race+\"_floor\"\n",
    "        df_receiving_votes.loc[:,add_var]=0.0\n",
    "        df_receiving_votes.loc[:,rem_var]=0.0\n",
    "        df_receiving_votes.loc[:,floor_var]=0.0\n",
    "\n",
    "    #Iterate over the rows\n",
    "    #Note this function iterates over the dataframe two times so the rounded vote totals match the totals to allocate\n",
    "    for index, row in df_receiving_votes.iterrows():\n",
    "        if row[col_allocating] in to_dole_out_totals[col_allocating].unique():\n",
    "            for race in column_list:\n",
    "                add_var = race+\"_add\"\n",
    "                rem_var = race+\"_rem\"\n",
    "                floor_var = race+\"_floor\"\n",
    "                #Grab the district\n",
    "                county_id = row[col_allocating]\n",
    "                if [county_id,race] in special_allocation_needed:\n",
    "                    #Get the denominator for the allocation - the summed \"total votes\" for precincts in that grouping\n",
    "                    denom = precinct_specific_totals.loc[precinct_specific_totals[col_allocating]==county_id][\"Total_Votes\"]\n",
    "                    #Get one of the numerators, how many districtwide votes to allocate\n",
    "                    numer = to_dole_out_totals.loc[to_dole_out_totals[col_allocating]==county_id][race]\n",
    "                    #Get the \"total votes\" for this particular precinct\n",
    "                    val = df_receiving_votes.at[index,\"Total_Votes\"]\n",
    "                    #Get the vote share, the precincts % of total precinct votes in the district times votes to allocate\n",
    "                else:\n",
    "                    #Get the denominator for the allocation (the precinct vote totals)\n",
    "                    denom = precinct_specific_totals.loc[precinct_specific_totals[col_allocating]==county_id][race]\n",
    "                    #Get one of the numerators, how many districtwide votes to allocate\n",
    "                    numer = to_dole_out_totals.loc[to_dole_out_totals[col_allocating]==county_id][race]\n",
    "                    #Get the vote totals for this race in this precinct\n",
    "                    val = df_receiving_votes.at[index,race]\n",
    "                    #Get the vote share, the precincts % of total precinct votes in the district times votes to allocate\n",
    "                if ((float(denom)==0)):\n",
    "                    vote_share = 0\n",
    "                else:\n",
    "                    vote_share = (float(val)/float(denom))*float(numer)\n",
    "                df_receiving_votes.at[index,add_var] = vote_share\n",
    "                #Take the decimal remainder of the allocation\n",
    "                df_receiving_votes.at[index,rem_var] = vote_share%1\n",
    "                #Take the floor of the allocation\n",
    "                df_receiving_votes.at[index,floor_var] = np.floor(vote_share)\n",
    "\n",
    "    #After the first pass through, get the sums of the races by district to assist in the rounding            \n",
    "    first_allocation = pd.DataFrame(df_receiving_votes.groupby([col_allocating]).sum())\n",
    "\n",
    "    #Now we want to iterate district by district to work on rounding\n",
    "    county_list = list(to_dole_out_totals[col_allocating].unique()) \n",
    "\n",
    "    #Iterate over the district\n",
    "    for county in county_list:\n",
    "        for race in column_list:\n",
    "            add_var = race+\"_add\"\n",
    "            rem_var = race+\"_rem\"\n",
    "            floor_var = race+\"_floor\"\n",
    "            #County how many votes still need to be allocated (because we took the floor of all the initial allocations)\n",
    "            to_go = int(np.round((int(to_dole_out_totals.loc[to_dole_out_totals[col_allocating]==county][race])-first_allocation.loc[first_allocation.index==county,floor_var])))\n",
    "            #Grab the n precincts with the highest remainders and round these up, where n is the # of votes that still need to be allocated\n",
    "            for index in df_receiving_votes.loc[df_receiving_votes[col_allocating]==county][rem_var].nlargest(to_go).index:\n",
    "                df_receiving_votes.at[index,add_var] = np.ceil(df_receiving_votes.at[index,add_var])\n",
    "\n",
    "    #Iterate over every race again\n",
    "    for race in column_list:\n",
    "        add_var = race+\"_add\"\n",
    "        #Round every allocation down to not add fractional votes\n",
    "        df_receiving_votes.loc[:,add_var]=np.floor(df_receiving_votes.loc[:,add_var])\n",
    "        df_receiving_votes.loc[:,race]+=df_receiving_votes.loc[:,add_var]\n",
    "        df_receiving_votes.loc[:,race] = df_receiving_votes.loc[:,race].astype(int)\n",
    "        \n",
    "    df_receiving_votes = df_receiving_votes[original_cols]\n",
    "    \n",
    "    return df_receiving_votes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
